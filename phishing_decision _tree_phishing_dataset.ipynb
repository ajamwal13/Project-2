{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "phiusiil_phishing_url_website = fetch_ucirepo(id=967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tj/k2qhl9wn4k1b8qp9bzfzdhrm0000gn/T/ipykernel_79487/2944218098.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(['URL', 'TLD', 'Domain', 'Title'], inplace=True, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# data (as pandas dataframes)\n",
    "X = phiusiil_phishing_url_website.data.features\n",
    "y = phiusiil_phishing_url_website.data.targets\n",
    "\n",
    "X.dtypes\n",
    "# Drop Non Numeric\n",
    "X.drop(['URL', 'TLD', 'Domain', 'Title'], inplace=True, axis=1)\n",
    "X.to_csv(\"phishing_url.csv\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URLLength                       int64\n",
       "DomainLength                    int64\n",
       "IsDomainIP                      int64\n",
       "URLSimilarityIndex            float64\n",
       "CharContinuationRate          float64\n",
       "TLDLegitimateProb             float64\n",
       "URLCharProb                   float64\n",
       "TLDLength                       int64\n",
       "NoOfSubDomain                   int64\n",
       "HasObfuscation                  int64\n",
       "NoOfObfuscatedChar              int64\n",
       "ObfuscationRatio              float64\n",
       "NoOfLettersInURL                int64\n",
       "LetterRatioInURL              float64\n",
       "NoOfDegitsInURL                 int64\n",
       "DegitRatioInURL               float64\n",
       "NoOfEqualsInURL                 int64\n",
       "NoOfQMarkInURL                  int64\n",
       "NoOfAmpersandInURL              int64\n",
       "NoOfOtherSpecialCharsInURL      int64\n",
       "SpacialCharRatioInURL         float64\n",
       "IsHTTPS                         int64\n",
       "LineOfCode                      int64\n",
       "LargestLineLength               int64\n",
       "HasTitle                        int64\n",
       "DomainTitleMatchScore         float64\n",
       "URLTitleMatchScore            float64\n",
       "HasFavicon                      int64\n",
       "Robots                          int64\n",
       "IsResponsive                    int64\n",
       "NoOfURLRedirect                 int64\n",
       "NoOfSelfRedirect                int64\n",
       "HasDescription                  int64\n",
       "NoOfPopup                       int64\n",
       "NoOfiFrame                      int64\n",
       "HasExternalFormSubmit           int64\n",
       "HasSocialNet                    int64\n",
       "HasSubmitButton                 int64\n",
       "HasHiddenFields                 int64\n",
       "HasPasswordField                int64\n",
       "Bank                            int64\n",
       "Pay                             int64\n",
       "Crypto                          int64\n",
       "HasCopyrightInfo                int64\n",
       "NoOfImage                       int64\n",
       "NoOfCSS                         int64\n",
       "NoOfJS                          int64\n",
       "NoOfSelfRef                     int64\n",
       "NoOfEmptyRef                    int64\n",
       "NoOfExternalRef                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier:  Un-Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 1.0\n",
      "Accuracy Score : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25321\n",
      "           1       1.00      1.00      1.00     33628\n",
      "\n",
      "    accuracy                           1.00     58949\n",
      "   macro avg       1.00      1.00      1.00     58949\n",
      "weighted avg       1.00      1.00      1.00     58949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create the decision tree classifier instance\n",
    "model_not_scaled = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Fit the model - without scaling\n",
    "model_not_scaled = model_not_scaled.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {model_not_scaled.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model_not_scaled.score(X_test, y_test)}\")\n",
    "\n",
    "# Making predictions using the testing data - without scaling\n",
    "predictions = model_not_scaled.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "\n",
    "feature_importances = model_not_scaled.tree_.compute_feature_importances(normalize=False)\n",
    "#print(\"feat importance: model_not_scaled = \" + str(feature_importances))\n",
    "importances_sorted = sorted(zip(feature_importances, X.columns), reverse=True)\n",
    "importances_sorted[:10]\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier: Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 1.0\n",
      "Accuracy Score : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.48310272154564027, 'URLSimilarityIndex'),\n",
       " (0.006217841735266813, 'LineOfCode'),\n",
       " (0.00019222158898808743, 'IsHTTPS'),\n",
       " (1.1309163009894951e-05, 'NoOfSubDomain'),\n",
       " (0.0, 'URLTitleMatchScore'),\n",
       " (0.0, 'URLLength'),\n",
       " (0.0, 'URLCharProb'),\n",
       " (0.0, 'TLDLength'),\n",
       " (0.0, 'TLDLegitimateProb'),\n",
       " (0.0, 'SpacialCharRatioInURL')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler with the training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the training data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create the decision tree classifier instance\n",
    "model_scaled = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model - With Scaling\n",
    "model_scaled = model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {model_not_scaled.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model_not_scaled.score(X_test, y_test)}\")\n",
    "\n",
    "# Making predictions using the testing data - without scaling\n",
    "predictions = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "\n",
    "feat_importance = model_scaled.tree_.compute_feature_importances(normalize=False)\n",
    "#print(\"feat importance: model_scaled: = \" + str(feat_importance))\n",
    "importances_sorted = sorted(zip(feature_importances, X.columns), reverse=True)\n",
    "importances_sorted[:10]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
