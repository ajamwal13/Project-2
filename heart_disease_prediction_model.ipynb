{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (as pandas dataframes)\n",
    "X = heart_disease.data.features\n",
    "y = heart_disease.data.targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = X.join(y)\n",
    "data = data.dropna()\n",
    "X = data.drop('num', axis=1)\n",
    "y = data['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   1       145   233    1        2      150      0      2.3   \n",
       "1     67    1   4       160   286    0        2      108      1      1.5   \n",
       "2     67    1   4       120   229    0        2      129      1      2.6   \n",
       "3     37    1   3       130   250    0        0      187      0      3.5   \n",
       "4     41    0   2       130   204    0        2      172      0      1.4   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "297   57    0   4       140   241    0        0      123      1      0.2   \n",
       "298   45    1   1       110   264    0        0      132      0      1.2   \n",
       "299   68    1   4       144   193    1        0      141      0      3.4   \n",
       "300   57    1   4       130   131    0        0      115      1      1.2   \n",
       "301   57    0   2       130   236    0        2      174      0      0.0   \n",
       "\n",
       "     slope   ca  thal  \n",
       "0        3  0.0   6.0  \n",
       "1        2  3.0   3.0  \n",
       "2        2  2.0   7.0  \n",
       "3        3  0.0   3.0  \n",
       "4        1  0.0   3.0  \n",
       "..     ...  ...   ...  \n",
       "297      2  0.0   7.0  \n",
       "298      2  0.0   7.0  \n",
       "299      2  2.0   7.0  \n",
       "300      2  1.0   7.0  \n",
       "301      2  1.0   3.0  \n",
       "\n",
       "[297 rows x 13 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      2\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "297    1\n",
       "298    1\n",
       "299    2\n",
       "300    3\n",
       "301    1\n",
       "Name: num, Length: 297, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuzhinjo/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6351351351351351\n",
      "Testing Data Score: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Score the model\n",
    "print(f\"Training Data Score: {logistic_regression_model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8648648648648649\n",
      "Testing Data Score: 0.7866666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuzhinjo/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "# Score the model\n",
    "print(f\"Training Data Score: {logistic_regression_model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7733333333333333\n",
      "feat importance: model_not_scaled = [0.04481948 0.00675676 0.16201258 0.02099232 0.03987011 0.\n",
      " 0.0045045  0.0263238  0.03741098 0.05365479 0.         0.06551243\n",
      " 0.03749295]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the decision tree classifier instance\n",
    "model_not_scaled = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Fit the model - without scaling\n",
    "model_not_scaled = model_not_scaled.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions using the testing data - without scaling\n",
    "predictions = model_not_scaled.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "\n",
    "feat_importance = model_not_scaled.tree_.compute_feature_importances(normalize=False)\n",
    "print(\"feat importance: model_not_scaled = \" + str(feat_importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.76\n",
      "feat importance: model_scaled: = [0.05908375 0.00720721 0.15750807 0.03060193 0.03905977 0.0045045\n",
      " 0.         0.0248223  0.03741098 0.02933047 0.         0.07232877\n",
      " 0.03749295]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler with the training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the training data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create the decision tree classifier instance\n",
    "model_scaled = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model - With Scaling\n",
    "model_scaled = model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions using the testing data - without scaling\n",
    "predictions = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "\n",
    "feat_importance = model_scaled.tree_.compute_feature_importances(normalize=False)\n",
    "print(\"feat importance: model_scaled: = \" + str(feat_importance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "# Create DOT data\n",
    "dot_data = tree.export_graphviz(\n",
    "    model_not_scaled, out_file=None, feature_names=X.columns, class_names=[\"0\", \"1\"], filled=True, max_depth=5\n",
    ")\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())\n",
    "\n",
    "# Save the tree as PDF\n",
    "file_path = \"heart_disease_prediction_dt.pdf\"\n",
    "graph.write_pdf(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092399</td>\n",
       "      <td>0.110471</td>\n",
       "      <td>0.290476</td>\n",
       "      <td>0.202644</td>\n",
       "      <td>0.132062</td>\n",
       "      <td>0.149917</td>\n",
       "      <td>-0.394563</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>0.197123</td>\n",
       "      <td>0.159405</td>\n",
       "      <td>0.362210</td>\n",
       "      <td>0.126586</td>\n",
       "      <td>0.227075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.092399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>-0.066340</td>\n",
       "      <td>-0.198089</td>\n",
       "      <td>0.038850</td>\n",
       "      <td>0.033897</td>\n",
       "      <td>-0.060496</td>\n",
       "      <td>0.143581</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.091925</td>\n",
       "      <td>0.383652</td>\n",
       "      <td>0.278467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>0.110471</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036980</td>\n",
       "      <td>0.072088</td>\n",
       "      <td>-0.057663</td>\n",
       "      <td>0.063905</td>\n",
       "      <td>-0.339308</td>\n",
       "      <td>0.377525</td>\n",
       "      <td>0.203244</td>\n",
       "      <td>0.151079</td>\n",
       "      <td>0.235644</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.408945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>0.290476</td>\n",
       "      <td>-0.066340</td>\n",
       "      <td>-0.036980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131536</td>\n",
       "      <td>0.180860</td>\n",
       "      <td>0.149242</td>\n",
       "      <td>-0.049108</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>0.191243</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>0.138183</td>\n",
       "      <td>0.153490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.202644</td>\n",
       "      <td>-0.198089</td>\n",
       "      <td>0.072088</td>\n",
       "      <td>0.131536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012708</td>\n",
       "      <td>0.165046</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>-0.009215</td>\n",
       "      <td>0.115945</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>0.080285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>0.132062</td>\n",
       "      <td>0.038850</td>\n",
       "      <td>-0.057663</td>\n",
       "      <td>0.180860</td>\n",
       "      <td>0.012708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.008311</td>\n",
       "      <td>0.047819</td>\n",
       "      <td>0.152086</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>0.003167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>0.149917</td>\n",
       "      <td>0.033897</td>\n",
       "      <td>0.063905</td>\n",
       "      <td>0.149242</td>\n",
       "      <td>0.165046</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.072290</td>\n",
       "      <td>0.081874</td>\n",
       "      <td>0.113726</td>\n",
       "      <td>0.135141</td>\n",
       "      <td>0.129021</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>0.166343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>-0.394563</td>\n",
       "      <td>-0.060496</td>\n",
       "      <td>-0.339308</td>\n",
       "      <td>-0.049108</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>-0.072290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.384368</td>\n",
       "      <td>-0.347640</td>\n",
       "      <td>-0.389307</td>\n",
       "      <td>-0.268727</td>\n",
       "      <td>-0.274831</td>\n",
       "      <td>-0.423817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>0.096489</td>\n",
       "      <td>0.143581</td>\n",
       "      <td>0.377525</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.081874</td>\n",
       "      <td>-0.384368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289310</td>\n",
       "      <td>0.250572</td>\n",
       "      <td>0.148232</td>\n",
       "      <td>0.326927</td>\n",
       "      <td>0.421355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.197123</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>0.203244</td>\n",
       "      <td>0.191243</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>0.008311</td>\n",
       "      <td>0.113726</td>\n",
       "      <td>-0.347640</td>\n",
       "      <td>0.289310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579037</td>\n",
       "      <td>0.294452</td>\n",
       "      <td>0.344976</td>\n",
       "      <td>0.424052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>0.159405</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.151079</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>-0.009215</td>\n",
       "      <td>0.047819</td>\n",
       "      <td>0.135141</td>\n",
       "      <td>-0.389307</td>\n",
       "      <td>0.250572</td>\n",
       "      <td>0.579037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109761</td>\n",
       "      <td>0.279688</td>\n",
       "      <td>0.333049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.362210</td>\n",
       "      <td>0.091925</td>\n",
       "      <td>0.235644</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>0.115945</td>\n",
       "      <td>0.152086</td>\n",
       "      <td>0.129021</td>\n",
       "      <td>-0.268727</td>\n",
       "      <td>0.148232</td>\n",
       "      <td>0.294452</td>\n",
       "      <td>0.109761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.256382</td>\n",
       "      <td>0.463189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>0.126586</td>\n",
       "      <td>0.383652</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.138183</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>-0.274831</td>\n",
       "      <td>0.326927</td>\n",
       "      <td>0.344976</td>\n",
       "      <td>0.279688</td>\n",
       "      <td>0.256382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.526640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>0.227075</td>\n",
       "      <td>0.278467</td>\n",
       "      <td>0.408945</td>\n",
       "      <td>0.153490</td>\n",
       "      <td>0.080285</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.166343</td>\n",
       "      <td>-0.423817</td>\n",
       "      <td>0.421355</td>\n",
       "      <td>0.424052</td>\n",
       "      <td>0.333049</td>\n",
       "      <td>0.463189</td>\n",
       "      <td>0.526640</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       sex        cp  trestbps      chol       fbs  \\\n",
       "age       1.000000 -0.092399  0.110471  0.290476  0.202644  0.132062   \n",
       "sex      -0.092399  1.000000  0.008908 -0.066340 -0.198089  0.038850   \n",
       "cp        0.110471  0.008908  1.000000 -0.036980  0.072088 -0.057663   \n",
       "trestbps  0.290476 -0.066340 -0.036980  1.000000  0.131536  0.180860   \n",
       "chol      0.202644 -0.198089  0.072088  0.131536  1.000000  0.012708   \n",
       "fbs       0.132062  0.038850 -0.057663  0.180860  0.012708  1.000000   \n",
       "restecg   0.149917  0.033897  0.063905  0.149242  0.165046  0.068831   \n",
       "thalach  -0.394563 -0.060496 -0.339308 -0.049108 -0.000075 -0.007842   \n",
       "exang     0.096489  0.143581  0.377525  0.066691  0.059339 -0.000893   \n",
       "oldpeak   0.197123  0.106567  0.203244  0.191243  0.038596  0.008311   \n",
       "slope     0.159405  0.033345  0.151079  0.121172 -0.009215  0.047819   \n",
       "ca        0.362210  0.091925  0.235644  0.097954  0.115945  0.152086   \n",
       "thal      0.126586  0.383652  0.268500  0.138183  0.010859  0.062209   \n",
       "num       0.227075  0.278467  0.408945  0.153490  0.080285  0.003167   \n",
       "\n",
       "           restecg   thalach     exang   oldpeak     slope        ca  \\\n",
       "age       0.149917 -0.394563  0.096489  0.197123  0.159405  0.362210   \n",
       "sex       0.033897 -0.060496  0.143581  0.106567  0.033345  0.091925   \n",
       "cp        0.063905 -0.339308  0.377525  0.203244  0.151079  0.235644   \n",
       "trestbps  0.149242 -0.049108  0.066691  0.191243  0.121172  0.097954   \n",
       "chol      0.165046 -0.000075  0.059339  0.038596 -0.009215  0.115945   \n",
       "fbs       0.068831 -0.007842 -0.000893  0.008311  0.047819  0.152086   \n",
       "restecg   1.000000 -0.072290  0.081874  0.113726  0.135141  0.129021   \n",
       "thalach  -0.072290  1.000000 -0.384368 -0.347640 -0.389307 -0.268727   \n",
       "exang     0.081874 -0.384368  1.000000  0.289310  0.250572  0.148232   \n",
       "oldpeak   0.113726 -0.347640  0.289310  1.000000  0.579037  0.294452   \n",
       "slope     0.135141 -0.389307  0.250572  0.579037  1.000000  0.109761   \n",
       "ca        0.129021 -0.268727  0.148232  0.294452  0.109761  1.000000   \n",
       "thal      0.018795 -0.274831  0.326927  0.344976  0.279688  0.256382   \n",
       "num       0.166343 -0.423817  0.421355  0.424052  0.333049  0.463189   \n",
       "\n",
       "              thal       num  \n",
       "age       0.126586  0.227075  \n",
       "sex       0.383652  0.278467  \n",
       "cp        0.268500  0.408945  \n",
       "trestbps  0.138183  0.153490  \n",
       "chol      0.010859  0.080285  \n",
       "fbs       0.062209  0.003167  \n",
       "restecg   0.018795  0.166343  \n",
       "thalach  -0.274831 -0.423817  \n",
       "exang     0.326927  0.421355  \n",
       "oldpeak   0.344976  0.424052  \n",
       "slope     0.279688  0.333049  \n",
       "ca        0.256382  0.463189  \n",
       "thal      1.000000  0.526640  \n",
       "num       0.526640  1.000000  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([X, y], axis=1)\n",
    "combined_df_0 = combined_df.loc[[0]]\n",
    "combined_df_0.to_csv(\"heart_disease_data_0.csv\", index=False, header=True)\n",
    "combined_df_1 = combined_df.loc[[1]]\n",
    "combined_df_1.to_csv(\"heart_disease_data_1.csv\", index=False, header=True)\n",
    "\n",
    "combined_df[[\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\",\"thalach\",\n",
    "            \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "\n",
       "    ca  thal  num  \n",
       "0  0.0   6.0    0  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_1 = pd.read_csv(\"heart_disease_data_0.csv\")\n",
    "combined_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [[1. 0.]]\n",
      "feat importance: Real Data: Not Scaled = [0.04481948 0.00675676 0.16201258 0.02099232 0.03987011 0.\n",
      " 0.0045045  0.0263238  0.03741098 0.05365479 0.         0.06551243\n",
      " 0.03749295]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = combined_df_1.drop('num', axis=1)\n",
    "y = combined_df_1['num']\n",
    "predictions_new =  model_not_scaled.predict(X)\n",
    "\n",
    "#DecisionTreeClassifier\n",
    "model_not_scaled.predict_proba(X)\n",
    "print(\"Prediction: \", model_not_scaled.predict_proba(X))\n",
    "\n",
    "feat_importance = model_not_scaled.tree_.compute_feature_importances(normalize=False)\n",
    "print(\"feat importance: Real Data: Not Scaled = \" + str(feat_importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[209], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m combined_df_0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Splitting into Train and Test sets\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Making predictions using the testing data - without scaling\u001b[39;00m\n\u001b[1;32m     11\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model_not_scaled\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2277\u001b[0m     )\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=1, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = combined_df_0.drop(columns='num')\n",
    "y = combined_df_0['num'].values.reshape(-1, 1)\n",
    "\n",
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Making predictions using the testing data - without scaling\n",
    "predictions = model_not_scaled.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score : {acc_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
